{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Manuel Aragon\n",
    "#CSCE 4290 INTRODUCTION TO NATURAL LANGUAGE PROCESSING\n",
    "#Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus:\n",
      "[['B', 'a', 'k', 'e', 'r', '_'], ['B', 'e', 't', 't', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'u', 't', 't', 'e', 'r', '.', '_'], ['B', 'u', 't', ',', '_'], ['i', 't', '_'], ['m', 'a', 'd', 'e', '_'], ['h', 'e', 'r', '_'], ['b', 'a', 't', 't', 'e', 'r', '_'], ['b', 'i', 't', 't', 'e', 'r', '.', '_'], ['S', 'o', ',', '_'], ['B', 'a', 'k', 'e', 'r', '_'], ['B', 'e', 't', 't', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'e', 't', 't', 'e', 'r', '_'], ['b', 'u', 't', 't', 'e', 'r', '_'], ['t', 'o', '_'], ['m', 'a', 'k', 'e', '_'], ['h', 'e', 'r', '_'], ['b', 'i', 't', 't', 'e', 'r', '_'], ['b', 'a', 't', 't', 'e', 'r', '_'], ['b', 'e', 't', 't', 'e', 'r', '.', '_']]\n",
      "Vocabulary:\n",
      "{'m', 'h', 'o', 'u', 'S', '.', 'a', 'k', 'B', 'e', 'b', 'd', ',', 'g', '_', 'L', 'r', 't', 'y', 's', 'i'}\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "\n",
    "#input:\n",
    "original_corpus = \"Baker Betty Lou bought some butter. But, it made her batter bitter. So, Baker Betty Lou bought some better butter to make her bitter batter better.\"\n",
    "original_corpus = original_corpus.split()\n",
    "\n",
    "#add end of word tokens\n",
    "marked_corpus = [c + '_' for c in original_corpus]\n",
    "# initialize the vocabulary as the set of all individual characters\n",
    "vocab = set(\"\".join(marked_corpus))\n",
    "\n",
    "\n",
    "corpus = [[token for token in word] for word in marked_corpus]\n",
    "print(\"Corpus:\")\n",
    "print(corpus)\n",
    "print(\"Vocabulary:\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in order:\n",
      "Counter({('e', 'r'): 12, ('t', 't'): 10, ('r', '_'): 9, ('t', 'e'): 8, ('e', 't'): 4, ('o', 'u'): 4, ('e', '_'): 4, ('a', 'k'): 3, ('k', 'e'): 3, ('t', '_'): 3, ('u', 't'): 3, ('r', '.'): 3, ('.', '_'): 3, ('i', 't'): 3, ('B', 'a'): 2, ('B', 'e'): 2, ('t', 'y'): 2, ('y', '_'): 2, ('L', 'o'): 2, ('u', '_'): 2, ('b', 'o'): 2, ('u', 'g'): 2, ('g', 'h'): 2, ('h', 't'): 2, ('s', 'o'): 2, ('o', 'm'): 2, ('m', 'e'): 2, ('b', 'u'): 2, (',', '_'): 2, ('m', 'a'): 2, ('h', 'e'): 2, ('b', 'a'): 2, ('a', 't'): 2, ('b', 'i'): 2, ('b', 'e'): 2, ('B', 'u'): 1, ('t', ','): 1, ('a', 'd'): 1, ('d', 'e'): 1, ('S', 'o'): 1, ('o', ','): 1, ('t', 'o'): 1, ('o', '_'): 1})\n",
      "Most Common:\n",
      "('e', 'r')\n",
      "Vocab addition:er\n",
      "Updated Corpus\n",
      "[['B', 'a', 'k', 'er', '_'], ['B', 'e', 't', 't', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'u', 't', 't', 'er', '.', '_'], ['B', 'u', 't', ',', '_'], ['i', 't', '_'], ['m', 'a', 'd', 'e', '_'], ['h', 'er', '_'], ['b', 'a', 't', 't', 'er', '_'], ['b', 'i', 't', 't', 'er', '.', '_'], ['S', 'o', ',', '_'], ['B', 'a', 'k', 'er', '_'], ['B', 'e', 't', 't', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'e', 't', 't', 'er', '_'], ['b', 'u', 't', 't', 'er', '_'], ['t', 'o', '_'], ['m', 'a', 'k', 'e', '_'], ['h', 'er', '_'], ['b', 'i', 't', 't', 'er', '_'], ['b', 'a', 't', 't', 'er', '_'], ['b', 'e', 't', 't', 'er', '.', '_']]\n",
      "Updated Vocabulary\n",
      "{'er', 'm', 'h', 'o', 'u', 'S', '.', 'a', 'k', 'B', 'e', 'b', 'd', ',', 'g', '_', 'L', 'r', 't', 'y', 's', 'i'}\n"
     ]
    }
   ],
   "source": [
    "#k = 1\n",
    "import collections\n",
    "\n",
    "#count the number of adjacent tokens\n",
    "counter = collections.Counter()\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        counter[(char_list[i], char_list[i+1])] += 1\n",
    "\n",
    "most_common = counter.most_common(1)[0]\n",
    "print(\"Count in order:\")\n",
    "print(counter)\n",
    "print(\"Most Common:\")\n",
    "print(most_common[0])\n",
    "\n",
    "#merge tokens and update corpus\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        if (char_list[i], char_list[i+1]) == most_common[0]:\n",
    "            #make new token by concatenating\n",
    "            merged_symbol = str(char_list[i] + char_list[i+1])\n",
    "            \n",
    "            #update vocabulary\n",
    "            vocab.add(merged_symbol)\n",
    "            #update corpus\n",
    "            char_list[i] = merged_symbol\n",
    "            del char_list[i + 1]\n",
    "            break\n",
    "print(\"Vocab addition:\" + merged_symbol)\n",
    "print(\"Updated Corpus\")\n",
    "print(corpus)\n",
    "print(\"Updated Vocabulary\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in order:\n",
      "Counter({('t', 't'): 10, ('er', '_'): 9, ('t', 'er'): 8, ('e', 't'): 4, ('o', 'u'): 4, ('e', '_'): 4, ('a', 'k'): 3, ('t', '_'): 3, ('u', 't'): 3, ('er', '.'): 3, ('.', '_'): 3, ('i', 't'): 3, ('B', 'a'): 2, ('k', 'er'): 2, ('B', 'e'): 2, ('t', 'y'): 2, ('y', '_'): 2, ('L', 'o'): 2, ('u', '_'): 2, ('b', 'o'): 2, ('u', 'g'): 2, ('g', 'h'): 2, ('h', 't'): 2, ('s', 'o'): 2, ('o', 'm'): 2, ('m', 'e'): 2, ('b', 'u'): 2, (',', '_'): 2, ('m', 'a'): 2, ('h', 'er'): 2, ('b', 'a'): 2, ('a', 't'): 2, ('b', 'i'): 2, ('b', 'e'): 2, ('B', 'u'): 1, ('t', ','): 1, ('a', 'd'): 1, ('d', 'e'): 1, ('S', 'o'): 1, ('o', ','): 1, ('t', 'o'): 1, ('o', '_'): 1, ('k', 'e'): 1})\n",
      "Most Common:\n",
      "('t', 't')\n",
      "Vocab addition:tt\n",
      "Updated Corpus\n",
      "[['B', 'a', 'k', 'er', '_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'u', 'tt', 'er', '.', '_'], ['B', 'u', 't', ',', '_'], ['i', 't', '_'], ['m', 'a', 'd', 'e', '_'], ['h', 'er', '_'], ['b', 'a', 'tt', 'er', '_'], ['b', 'i', 'tt', 'er', '.', '_'], ['S', 'o', ',', '_'], ['B', 'a', 'k', 'er', '_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'e', 'tt', 'er', '_'], ['b', 'u', 'tt', 'er', '_'], ['t', 'o', '_'], ['m', 'a', 'k', 'e', '_'], ['h', 'er', '_'], ['b', 'i', 'tt', 'er', '_'], ['b', 'a', 'tt', 'er', '_'], ['b', 'e', 'tt', 'er', '.', '_']]\n",
      "Updated Vocabulary\n",
      "{'tt', 'er', 'm', 'h', 'o', 'u', 'S', '.', 'a', 'k', 'B', 'e', 'b', 'd', ',', 'g', '_', 'L', 'r', 't', 'y', 's', 'i'}\n"
     ]
    }
   ],
   "source": [
    "#k = 2\n",
    "import collections\n",
    "\n",
    "#count the number of adjacent tokens\n",
    "counter = collections.Counter()\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        counter[(char_list[i], char_list[i+1])] += 1\n",
    "\n",
    "most_common = counter.most_common(1)[0]\n",
    "print(\"Count in order:\")\n",
    "print(counter)\n",
    "print(\"Most Common:\")\n",
    "print(most_common[0])\n",
    "\n",
    "#merge tokens and update corpus\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        if (char_list[i], char_list[i+1]) == most_common[0]:\n",
    "            #make new token by concatenating\n",
    "            merged_symbol = str(char_list[i] + char_list[i+1])\n",
    "            \n",
    "            #update vocabulary\n",
    "            vocab.add(merged_symbol)\n",
    "            #update corpus\n",
    "            char_list[i] = merged_symbol\n",
    "            del char_list[i + 1]\n",
    "            break\n",
    "print(\"Vocab addition:\" + merged_symbol)\n",
    "print(\"Updated Corpus\")\n",
    "print(corpus)\n",
    "print(\"Updated Vocabulary\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in order:\n",
      "Counter({('er', '_'): 9, ('tt', 'er'): 8, ('e', 'tt'): 4, ('o', 'u'): 4, ('e', '_'): 4, ('a', 'k'): 3, ('t', '_'): 3, ('er', '.'): 3, ('.', '_'): 3, ('B', 'a'): 2, ('k', 'er'): 2, ('B', 'e'): 2, ('tt', 'y'): 2, ('y', '_'): 2, ('L', 'o'): 2, ('u', '_'): 2, ('b', 'o'): 2, ('u', 'g'): 2, ('g', 'h'): 2, ('h', 't'): 2, ('s', 'o'): 2, ('o', 'm'): 2, ('m', 'e'): 2, ('b', 'u'): 2, ('u', 'tt'): 2, (',', '_'): 2, ('m', 'a'): 2, ('h', 'er'): 2, ('b', 'a'): 2, ('a', 'tt'): 2, ('b', 'i'): 2, ('i', 'tt'): 2, ('b', 'e'): 2, ('B', 'u'): 1, ('u', 't'): 1, ('t', ','): 1, ('i', 't'): 1, ('a', 'd'): 1, ('d', 'e'): 1, ('S', 'o'): 1, ('o', ','): 1, ('t', 'o'): 1, ('o', '_'): 1, ('k', 'e'): 1})\n",
      "Most Common:\n",
      "('er', '_')\n",
      "Vocab addition:er_\n",
      "Updated Corpus\n",
      "[['B', 'a', 'k', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'u', 'tt', 'er', '.', '_'], ['B', 'u', 't', ',', '_'], ['i', 't', '_'], ['m', 'a', 'd', 'e', '_'], ['h', 'er_'], ['b', 'a', 'tt', 'er_'], ['b', 'i', 'tt', 'er', '.', '_'], ['S', 'o', ',', '_'], ['B', 'a', 'k', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'e', 'tt', 'er_'], ['b', 'u', 'tt', 'er_'], ['t', 'o', '_'], ['m', 'a', 'k', 'e', '_'], ['h', 'er_'], ['b', 'i', 'tt', 'er_'], ['b', 'a', 'tt', 'er_'], ['b', 'e', 'tt', 'er', '.', '_']]\n",
      "Updated Vocabulary\n",
      "{'tt', 'er', 'm', 'h', 'o', 'u', 'S', '.', 'a', 'k', 'er_', 'B', 'e', 'b', 'd', ',', 'g', '_', 'L', 'r', 't', 'y', 's', 'i'}\n"
     ]
    }
   ],
   "source": [
    "#k = 3\n",
    "import collections\n",
    "\n",
    "#count the number of adjacent tokens\n",
    "counter = collections.Counter()\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        counter[(char_list[i], char_list[i+1])] += 1\n",
    "\n",
    "most_common = counter.most_common(1)[0]\n",
    "print(\"Count in order:\")\n",
    "print(counter)\n",
    "print(\"Most Common:\")\n",
    "print(most_common[0])\n",
    "\n",
    "#merge tokens and update corpus\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        if (char_list[i], char_list[i+1]) == most_common[0]:\n",
    "            #make new token by concatenating\n",
    "            merged_symbol = str(char_list[i] + char_list[i+1])\n",
    "            \n",
    "            #update vocabulary\n",
    "            vocab.add(merged_symbol)\n",
    "            #update corpus\n",
    "            char_list[i] = merged_symbol\n",
    "            del char_list[i + 1]\n",
    "            break\n",
    "print(\"Vocab addition:\" + merged_symbol)\n",
    "print(\"Updated Corpus\")\n",
    "print(corpus)\n",
    "print(\"Updated Vocabulary\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in order:\n",
      "Counter({('tt', 'er_'): 5, ('e', 'tt'): 4, ('o', 'u'): 4, ('e', '_'): 4, ('a', 'k'): 3, ('t', '_'): 3, ('tt', 'er'): 3, ('er', '.'): 3, ('.', '_'): 3, ('B', 'a'): 2, ('k', 'er_'): 2, ('B', 'e'): 2, ('tt', 'y'): 2, ('y', '_'): 2, ('L', 'o'): 2, ('u', '_'): 2, ('b', 'o'): 2, ('u', 'g'): 2, ('g', 'h'): 2, ('h', 't'): 2, ('s', 'o'): 2, ('o', 'm'): 2, ('m', 'e'): 2, ('b', 'u'): 2, ('u', 'tt'): 2, (',', '_'): 2, ('m', 'a'): 2, ('h', 'er_'): 2, ('b', 'a'): 2, ('a', 'tt'): 2, ('b', 'i'): 2, ('i', 'tt'): 2, ('b', 'e'): 2, ('B', 'u'): 1, ('u', 't'): 1, ('t', ','): 1, ('i', 't'): 1, ('a', 'd'): 1, ('d', 'e'): 1, ('S', 'o'): 1, ('o', ','): 1, ('t', 'o'): 1, ('o', '_'): 1, ('k', 'e'): 1})\n",
      "Most Common:\n",
      "('tt', 'er_')\n",
      "Vocab addition:tter_\n",
      "Updated Corpus\n",
      "[['B', 'a', 'k', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'u', 'tt', 'er', '.', '_'], ['B', 'u', 't', ',', '_'], ['i', 't', '_'], ['m', 'a', 'd', 'e', '_'], ['h', 'er_'], ['b', 'a', 'tter_'], ['b', 'i', 'tt', 'er', '.', '_'], ['S', 'o', ',', '_'], ['B', 'a', 'k', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'o', 'u', '_'], ['b', 'o', 'u', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'e', 'tter_'], ['b', 'u', 'tter_'], ['t', 'o', '_'], ['m', 'a', 'k', 'e', '_'], ['h', 'er_'], ['b', 'i', 'tter_'], ['b', 'a', 'tter_'], ['b', 'e', 'tt', 'er', '.', '_']]\n",
      "Updated Vocabulary\n",
      "{'tt', 'er', 'm', 'h', 'o', 'u', 'S', '.', 'a', 'k', 'er_', 'B', 'e', 'b', 'd', ',', 'g', '_', 'tter_', 'L', 'r', 't', 'y', 's', 'i'}\n"
     ]
    }
   ],
   "source": [
    "#k = 4\n",
    "import collections\n",
    "\n",
    "#count the number of adjacent tokens\n",
    "counter = collections.Counter()\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        counter[(char_list[i], char_list[i+1])] += 1\n",
    "\n",
    "most_common = counter.most_common(1)[0]\n",
    "print(\"Count in order:\")\n",
    "print(counter)\n",
    "print(\"Most Common:\")\n",
    "print(most_common[0])\n",
    "\n",
    "#merge tokens and update corpus\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        if (char_list[i], char_list[i+1]) == most_common[0]:\n",
    "            #make new token by concatenating\n",
    "            merged_symbol = str(char_list[i] + char_list[i+1])\n",
    "            \n",
    "            #update vocabulary\n",
    "            vocab.add(merged_symbol)\n",
    "            #update corpus\n",
    "            char_list[i] = merged_symbol\n",
    "            del char_list[i + 1]\n",
    "            break\n",
    "print(\"Vocab addition:\" + merged_symbol)\n",
    "print(\"Updated Corpus\")\n",
    "print(corpus)\n",
    "print(\"Updated Vocabulary\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in order:\n",
      "Counter({('o', 'u'): 4, ('e', '_'): 4, ('a', 'k'): 3, ('e', 'tt'): 3, ('t', '_'): 3, ('tt', 'er'): 3, ('er', '.'): 3, ('.', '_'): 3, ('B', 'a'): 2, ('k', 'er_'): 2, ('B', 'e'): 2, ('tt', 'y'): 2, ('y', '_'): 2, ('L', 'o'): 2, ('u', '_'): 2, ('b', 'o'): 2, ('u', 'g'): 2, ('g', 'h'): 2, ('h', 't'): 2, ('s', 'o'): 2, ('o', 'm'): 2, ('m', 'e'): 2, ('b', 'u'): 2, (',', '_'): 2, ('m', 'a'): 2, ('h', 'er_'): 2, ('b', 'a'): 2, ('a', 'tter_'): 2, ('b', 'i'): 2, ('b', 'e'): 2, ('u', 'tt'): 1, ('B', 'u'): 1, ('u', 't'): 1, ('t', ','): 1, ('i', 't'): 1, ('a', 'd'): 1, ('d', 'e'): 1, ('i', 'tt'): 1, ('S', 'o'): 1, ('o', ','): 1, ('e', 'tter_'): 1, ('u', 'tter_'): 1, ('t', 'o'): 1, ('o', '_'): 1, ('k', 'e'): 1, ('i', 'tter_'): 1})\n",
      "Most Common:\n",
      "('o', 'u')\n",
      "Vocab addition:ou\n",
      "Updated Corpus\n",
      "[['B', 'a', 'k', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'ou', '_'], ['b', 'ou', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'u', 'tt', 'er', '.', '_'], ['B', 'u', 't', ',', '_'], ['i', 't', '_'], ['m', 'a', 'd', 'e', '_'], ['h', 'er_'], ['b', 'a', 'tter_'], ['b', 'i', 'tt', 'er', '.', '_'], ['S', 'o', ',', '_'], ['B', 'a', 'k', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'ou', '_'], ['b', 'ou', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e', '_'], ['b', 'e', 'tter_'], ['b', 'u', 'tter_'], ['t', 'o', '_'], ['m', 'a', 'k', 'e', '_'], ['h', 'er_'], ['b', 'i', 'tter_'], ['b', 'a', 'tter_'], ['b', 'e', 'tt', 'er', '.', '_']]\n",
      "Updated Vocabulary\n",
      "{'tt', 'er', 'm', 'h', 'o', 'u', 'S', '.', 'a', 'k', 'er_', 'B', 'e', 'b', 'd', ',', 'g', '_', 'tter_', 'L', 'r', 't', 'y', 's', 'i', 'ou'}\n"
     ]
    }
   ],
   "source": [
    "#k = 5\n",
    "import collections\n",
    "\n",
    "#count the number of adjacent tokens\n",
    "counter = collections.Counter()\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        counter[(char_list[i], char_list[i+1])] += 1\n",
    "\n",
    "most_common = counter.most_common(1)[0]\n",
    "print(\"Count in order:\")\n",
    "print(counter)\n",
    "print(\"Most Common:\")\n",
    "print(most_common[0])\n",
    "\n",
    "#merge tokens and update corpus\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        if (char_list[i], char_list[i+1]) == most_common[0]:\n",
    "            #make new token by concatenating\n",
    "            merged_symbol = str(char_list[i] + char_list[i+1])\n",
    "            \n",
    "            #update vocabulary\n",
    "            vocab.add(merged_symbol)\n",
    "            #update corpus\n",
    "            char_list[i] = merged_symbol\n",
    "            del char_list[i + 1]\n",
    "            break\n",
    "print(\"Vocab addition:\" + merged_symbol)\n",
    "print(\"Updated Corpus\")\n",
    "print(corpus)\n",
    "print(\"Updated Vocabulary\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in order:\n",
      "Counter({('e', '_'): 4, ('a', 'k'): 3, ('e', 'tt'): 3, ('t', '_'): 3, ('tt', 'er'): 3, ('er', '.'): 3, ('.', '_'): 3, ('B', 'a'): 2, ('k', 'er_'): 2, ('B', 'e'): 2, ('tt', 'y'): 2, ('y', '_'): 2, ('L', 'ou'): 2, ('ou', '_'): 2, ('b', 'ou'): 2, ('ou', 'g'): 2, ('g', 'h'): 2, ('h', 't'): 2, ('s', 'o'): 2, ('o', 'm'): 2, ('m', 'e'): 2, ('b', 'u'): 2, (',', '_'): 2, ('m', 'a'): 2, ('h', 'er_'): 2, ('b', 'a'): 2, ('a', 'tter_'): 2, ('b', 'i'): 2, ('b', 'e'): 2, ('u', 'tt'): 1, ('B', 'u'): 1, ('u', 't'): 1, ('t', ','): 1, ('i', 't'): 1, ('a', 'd'): 1, ('d', 'e'): 1, ('i', 'tt'): 1, ('S', 'o'): 1, ('o', ','): 1, ('e', 'tter_'): 1, ('u', 'tter_'): 1, ('t', 'o'): 1, ('o', '_'): 1, ('k', 'e'): 1, ('i', 'tter_'): 1})\n",
      "Most Common:\n",
      "('e', '_')\n",
      "Vocab addition:e_\n",
      "Updated Corpus\n",
      "[['B', 'a', 'k', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'ou', '_'], ['b', 'ou', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e_'], ['b', 'u', 'tt', 'er', '.', '_'], ['B', 'u', 't', ',', '_'], ['i', 't', '_'], ['m', 'a', 'd', 'e_'], ['h', 'er_'], ['b', 'a', 'tter_'], ['b', 'i', 'tt', 'er', '.', '_'], ['S', 'o', ',', '_'], ['B', 'a', 'k', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'ou', '_'], ['b', 'ou', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e_'], ['b', 'e', 'tter_'], ['b', 'u', 'tter_'], ['t', 'o', '_'], ['m', 'a', 'k', 'e_'], ['h', 'er_'], ['b', 'i', 'tter_'], ['b', 'a', 'tter_'], ['b', 'e', 'tt', 'er', '.', '_']]\n",
      "Updated Vocabulary\n",
      "{'tt', 'er', 'm', 'h', 'o', 'u', 'S', '.', 'a', 'k', 'er_', 'B', 'e', 'b', 'd', ',', 'g', '_', 'e_', 'tter_', 'L', 'r', 't', 'y', 's', 'i', 'ou'}\n"
     ]
    }
   ],
   "source": [
    "#k = 6\n",
    "import collections\n",
    "\n",
    "#count the number of adjacent tokens\n",
    "counter = collections.Counter()\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        counter[(char_list[i], char_list[i+1])] += 1\n",
    "\n",
    "most_common = counter.most_common(1)[0]\n",
    "print(\"Count in order:\")\n",
    "print(counter)\n",
    "print(\"Most Common:\")\n",
    "print(most_common[0])\n",
    "\n",
    "#merge tokens and update corpus\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        if (char_list[i], char_list[i+1]) == most_common[0]:\n",
    "            #make new token by concatenating\n",
    "            merged_symbol = str(char_list[i] + char_list[i+1])\n",
    "            \n",
    "            #update vocabulary\n",
    "            vocab.add(merged_symbol)\n",
    "            #update corpus\n",
    "            char_list[i] = merged_symbol\n",
    "            del char_list[i + 1]\n",
    "            break\n",
    "print(\"Vocab addition:\" + merged_symbol)\n",
    "print(\"Updated Corpus\")\n",
    "print(corpus)\n",
    "print(\"Updated Vocabulary\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in order:\n",
      "Counter({('a', 'k'): 3, ('e', 'tt'): 3, ('t', '_'): 3, ('tt', 'er'): 3, ('er', '.'): 3, ('.', '_'): 3, ('B', 'a'): 2, ('k', 'er_'): 2, ('B', 'e'): 2, ('tt', 'y'): 2, ('y', '_'): 2, ('L', 'ou'): 2, ('ou', '_'): 2, ('b', 'ou'): 2, ('ou', 'g'): 2, ('g', 'h'): 2, ('h', 't'): 2, ('s', 'o'): 2, ('o', 'm'): 2, ('m', 'e_'): 2, ('b', 'u'): 2, (',', '_'): 2, ('m', 'a'): 2, ('h', 'er_'): 2, ('b', 'a'): 2, ('a', 'tter_'): 2, ('b', 'i'): 2, ('b', 'e'): 2, ('u', 'tt'): 1, ('B', 'u'): 1, ('u', 't'): 1, ('t', ','): 1, ('i', 't'): 1, ('a', 'd'): 1, ('d', 'e_'): 1, ('i', 'tt'): 1, ('S', 'o'): 1, ('o', ','): 1, ('e', 'tter_'): 1, ('u', 'tter_'): 1, ('t', 'o'): 1, ('o', '_'): 1, ('k', 'e_'): 1, ('i', 'tter_'): 1})\n",
      "Most Common:\n",
      "('a', 'k')\n",
      "Vocab addition:ak\n",
      "Updated Corpus\n",
      "[['B', 'ak', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'ou', '_'], ['b', 'ou', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e_'], ['b', 'u', 'tt', 'er', '.', '_'], ['B', 'u', 't', ',', '_'], ['i', 't', '_'], ['m', 'a', 'd', 'e_'], ['h', 'er_'], ['b', 'a', 'tter_'], ['b', 'i', 'tt', 'er', '.', '_'], ['S', 'o', ',', '_'], ['B', 'ak', 'er_'], ['B', 'e', 'tt', 'y', '_'], ['L', 'ou', '_'], ['b', 'ou', 'g', 'h', 't', '_'], ['s', 'o', 'm', 'e_'], ['b', 'e', 'tter_'], ['b', 'u', 'tter_'], ['t', 'o', '_'], ['m', 'ak', 'e_'], ['h', 'er_'], ['b', 'i', 'tter_'], ['b', 'a', 'tter_'], ['b', 'e', 'tt', 'er', '.', '_']]\n",
      "Updated Vocabulary\n",
      "{'tt', 'er', 'm', 'h', 'o', 'u', 'S', '.', 'a', 'k', 'er_', 'B', 'e', 'b', 'd', ',', 'g', '_', 'e_', 'tter_', 'L', 'r', 'ak', 't', 'y', 's', 'i', 'ou'}\n"
     ]
    }
   ],
   "source": [
    "#k = 7\n",
    "import collections\n",
    "\n",
    "#count the number of adjacent tokens\n",
    "counter = collections.Counter()\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        counter[(char_list[i], char_list[i+1])] += 1\n",
    "\n",
    "most_common = counter.most_common(1)[0]\n",
    "print(\"Count in order:\")\n",
    "print(counter)\n",
    "print(\"Most Common:\")\n",
    "print(most_common[0])\n",
    "\n",
    "#merge tokens and update corpus\n",
    "for char_list in corpus:\n",
    "    for i in range(len(char_list) - 1):\n",
    "        if (char_list[i], char_list[i+1]) == most_common[0]:\n",
    "            #make new token by concatenating\n",
    "            merged_symbol = str(char_list[i] + char_list[i+1])\n",
    "            \n",
    "            #update vocabulary\n",
    "            vocab.add(merged_symbol)\n",
    "            #update corpus\n",
    "            char_list[i] = merged_symbol\n",
    "            del char_list[i + 1]\n",
    "            break\n",
    "print(\"Vocab addition:\" + merged_symbol)\n",
    "print(\"Updated Corpus\")\n",
    "print(corpus)\n",
    "print(\"Updated Vocabulary\")\n",
    "print(vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
