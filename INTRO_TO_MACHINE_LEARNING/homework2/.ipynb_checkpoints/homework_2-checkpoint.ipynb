{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manuel Aragon\n",
    "#EUID:ma1162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading Training Data\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "X = digits.images.reshape((len(digits.images), -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default accuracy: 0.9916666666666667\n",
      "Best hyperparameters: {'C': 1, 'gamma': 0.001}\n",
      "Tuned Accuracy (Validation): 0.9909528648857917\n",
      "Final Accuracy (Test): 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train the SVM with default parameters on the training data\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the default accuracy\n",
    "default_accuracy = clf.score(X_test, y_test)\n",
    "print(\"Default accuracy:\", default_accuracy)\n",
    "\n",
    "# Define the range of values for hyperparameters gamma and C\n",
    "gamma_range = [10**i for i in range(-5, 6)]\n",
    "C_range = [10**i for i in range(-5, 6)]\n",
    "\n",
    "# Create a grid of hyperparameter values to search\n",
    "param_grid = {'gamma': gamma_range, 'C': C_range}\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Report the best hyperparameters and accuracy\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Tuned Accuracy (Validation):\", best_accuracy)\n",
    "\n",
    "# Retrain the SVM with the best hyperparameters on the training data.\n",
    "best_clf = SVC(**best_params, kernel='rbf')\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate final accuracy\n",
    "final_accuracy = best_clf.score(X_test, y_test)\n",
    "print(\"Final Accuracy (Test):\", final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default accuracy: 0.975\n",
      "Best hyperparameters: {'n_neighbors': 3}\n",
      "Accuracy (Validation): 0.98677651955091\n",
      "Final Accuracy (Test): 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Train the KNN with default parameters on the training data\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the default accuracy on the validation set\n",
    "default_accuracy = clf.score(X_test, y_test)\n",
    "print(\"Default accuracy:\", default_accuracy)\n",
    "\n",
    "# Define the range of values for hyperparameter k\n",
    "k_range = [1, 3, 4, 7, 9]\n",
    "\n",
    "# Create a grid of hyperparameter values to search\n",
    "param_grid = {'n_neighbors': k_range}\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Report the best hyperparameters and accuracy on the validation set\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Accuracy (Validation):\", best_accuracy)\n",
    "\n",
    "# Retrain the KNN with the best hyperparameters on the combined training and validation data\n",
    "best_clf = KNeighborsClassifier(**best_params)\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate final accuracy\n",
    "final_accuracy = best_clf.score(X_test, y_test)\n",
    "print(\"Final Accuracy (Test):\", final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default accuracy: 0.8444444444444444\n",
      "Best hyperparameters: {'min_samples_split': 5}\n",
      "Accuracy (Validation): 0.845501838946961\n",
      "Final Accuracy (Test): 0.8555555555555555\n"
     ]
    }
   ],
   "source": [
    "#decision trees\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Train the decision tree with default parameters on the training data\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the default accuracy on the validation set\n",
    "default_accuracy = clf.score(X_test, y_test)\n",
    "print(\"Default accuracy:\", default_accuracy)\n",
    "\n",
    "# Define the range of values for hyperparameter min_samples_split\n",
    "min_samples_split_range = [3, 5, 7, 9]\n",
    "\n",
    "# Create a grid of hyperparameter values to search\n",
    "param_grid = {'min_samples_split': min_samples_split_range}\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Report the best hyperparameters and accuracy on the validation set\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Accuracy (Validation):\", best_accuracy)\n",
    "\n",
    "# Retrain the decision tree with the best hyperparameters on the combined training and validation data\n",
    "best_clf = DecisionTreeClassifier(**best_params)\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate final accuracy\n",
    "final_accuracy = best_clf.score(X_test, y_test)\n",
    "print(\"Final Accuracy (Test):\", final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default accuracy: 0.95\n",
      "Best hyperparameters: {'C': 0.1}\n",
      "Accuracy (Validation): 0.9679829655439413\n",
      "Final Accuracy (Test): 0.9583333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manix/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Train the logistic regression with default parameters on the training data\n",
    "clf = LogisticRegression(penalty='l1', solver='liblinear')  #using liblinear in order to be able to use l1\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the default accuracy on the validation set\n",
    "default_accuracy = clf.score(X_test, y_test)\n",
    "print(\"Default accuracy:\", default_accuracy)\n",
    "\n",
    "# Define the range of values for hyperparameter C\n",
    "C_range = [10**i for i in range(-5, 6)]\n",
    "\n",
    "# Create a grid of hyperparameter values to search\n",
    "param_grid = {'C': C_range}\n",
    "\n",
    "# Perform a grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Report the best hyperparameters and accuracy on the validation set\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Accuracy (Validation):\", best_accuracy)\n",
    "\n",
    "# Retrain the logistic regression with the best hyperparameters on the combined training and validation data\n",
    "best_clf = LogisticRegression(penalty='l1', solver='saga', **best_params)\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate final accuracy\n",
    "final_accuracy = best_clf.score(X_test, y_test)\n",
    "print(\"Final Accuracy (Test):\", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model | Default validation accuracy | Tuned validation accuracy | Selected hyperparamaters | Final test set accuracy\n",
    "---:|:---:|:---:|:---:| ---\n",
    "SVM | 0.9916666666666667 | 0.9909528648857917| 'C': 1, 'gamma': 0.001 | 0.9916666666666667\n",
    "k-NN | 0.975 | 0.98677651955091| n_neighbors': 3 | 0.9833333333333333\n",
    "Decision Trees | 0.8444444444444444 | 0.845501838946961| min_samples_split': 5 | 0.8555555555555555\n",
    "Logistic Regression| 0.95 | 0.9679829655439413| 'C': 0.1| 0.9583333333333334\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refrences:\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
